import Array._
import scala.math._
import scala.util.Random
import java.net._
import org.apache.spark.rdd._
import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.blaze._

class CaffeTest() 
  extends Accelerator[Array[Float], Array[Float]] {

  val id: String = "VGG-16"

  def getArgNum(): Int = 0

  def getArg(idx: Int): Option[_] = None

  override def call(in: Array[Float]) {
//    (in, v.data).zipped.map(_ + _)
	  println("No CPU implementation")
  }
}

object TestApp {
  def main(args : Array[String]) {

    val conf = new SparkConf()
    conf.setAppName("TestApp")

    val sc = new SparkContext(conf)
    val acc = new BlazeRuntime(sc)

    var num_sample = 1
    var num_part = 1

    if (args.size == 2) {
      num_sample = args(0).toInt
      num_part = args(1).toInt
    }

    val data = new Array[Float](10);

	for (i <- 0 until 9) {
		data(i) = i
	}

    val rdd = sc.parallelize(data, num_part)
    val rdd_acc = acc.wrap(rdd)

    val res_acc = rdd_acc.map_acc(new CaffeTest).collect

//    val res_cpu = rdd.map(e => (e, bc_data.value).zipped.map(_ + _)).collect

	println(res_acc.deep.mkString("\n"))

    acc.stop()
  }
}

